{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 3: Neural Networks\n",
    "\n",
    "### Overview\n",
    "In this problem set, you'll explore the foundational concepts of neural networks, covering basic architecture, activation functions, forward propagation, regularization, and adaptive learning. You'll also complete coding exercises to implement neural network components and train a basic neural network. You will both complete this Python script (`ps3.ipynb`) and submit a LaTeX report (`ps3.tex` and `ps3.pdf`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Architecture of a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is composed of layers of neurons: input layer, hidden layer(s), and an output layer. Each neuron receives inputs, processes them, and passes the result to the next layer.\n",
    "\n",
    "In this section, you'll implement a basic 3-layer neural network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Activation functions introduce non-linearity into the network, allowing it to learn more complex patterns. Common functions include:\n",
    "\n",
    "- **Sigmoid**: S-shaped curve, useful for binary classifications.\n",
    "- **ReLU (Rectified Linear Unit)**: Outputs zero if input is negative, otherwise outputs the input.\n",
    "- **Leaky ReLU**: Similar to ReLU but with a small gradient for negative inputs.\n",
    "\n",
    "### Exercise:\n",
    "Write functions for each activation function and plot them over a range of inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propagation is the process of passing inputs through the network to generate an output.\n",
    "\n",
    "### Exercise:\n",
    "Implement forward propagation for a 3-layer neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Overfitting and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting occurs when a model learns the noise in the training data rather than the actual pattern. Regularization helps control this.\n",
    "\n",
    "Common techniques include:\n",
    "\n",
    "- **L2 Regularization**: Adds a penalty based on the sum of squared weights.\n",
    "- **Dropout**: Randomly ignores some neurons during training.\n",
    "\n",
    "### Exercise:\n",
    "Implement L2 regularization in the loss calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training involves adjusting the weights and biases to minimize the loss. A popular method is gradient descent.\n",
    "\n",
    "### Exercise:\n",
    "Implement a simple gradient descent loop to train the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adaptive Learning Rates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive learning rate methods, like Adam, adjust the learning rate based on past gradients, improving training stability.\n",
    "\n",
    "### Exercise:\n",
    "Implement a simple version of the Adam optimizer for gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
